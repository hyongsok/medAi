{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import configparser\n",
    "import csv\n",
    "import numpy as np\n",
    "import imageio\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from RetinaCheckerMultiClass import RetinaCheckerMultiClass\n",
    "from helper_functions import reduce_to_2_classes, AverageMeter, AccuracyMeter\n",
    "from make_default_config import get_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "config = get_config()\n",
    "config['network']['model'] = 'resnet18'\n",
    "config['network']['pretrained'] = 'False'\n",
    "config['network']['optimizer'] = 'Adam'\n",
    "config['network']['criterion'] = 'BCEWithLogitsLoss'\n",
    "config['network']['multiclass'] = 'True'\n",
    "\n",
    "config['files']['test path'] = 'D:\\\\Dropbox\\\\Data\\\\mini-set'\n",
    "config['input']['checkpoint'] = 'model-bin-example.ckpt'\n",
    "config['input']['evaluation only'] = 'True'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "rc = RetinaCheckerMultiClass()\n",
    "rc.initialize( config )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc.load_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(rc.test_loader.dataset)\n",
    "n_cols = 6\n",
    "n_rows = np.ceil(num_images/n_cols)\n",
    "classlabel = ['no DMR', 'mild NPDR', 'mod NPDR', 'severe NPDR', 'PDR']\n",
    "test_loader = torch.utils.data.DataLoader(dataset=rc.test_dataset,\n",
    "                                        batch_size=len(rc.test_dataset),\n",
    "                                        shuffle=False,\n",
    "                                        sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(int(n_rows), int(n_cols), True, True, figsize=(20,int(n_rows)*3))\n",
    "rc.model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    losses = AverageMeter()\n",
    "    accuracy = AccuracyMeter()\n",
    "\n",
    "    confusion = torch.zeros((rc.num_classes, rc.num_classes), dtype=torch.float)\n",
    "    counter = 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(rc.device)\n",
    "        labels = labels.to(rc.device)\n",
    "\n",
    "        outputs = rc.model(images)\n",
    "        loss = rc.criterion(outputs, labels)\n",
    "\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "\n",
    "        num_correct = rc._evaluate_performance( labels, outputs )\n",
    "\n",
    "        accuracy.update(num_correct, labels.size(0))\n",
    "        predicted = torch.nn.Sigmoid()(outputs)\n",
    "        for pred, lab in zip(predicted.argmax(1), labels.argmax(1)):\n",
    "            confusion[pred, lab] += 1\n",
    "        \n",
    "        for img, lab, out in zip(images, labels, outputs):\n",
    "            ii = int(counter/n_cols)\n",
    "            jj = int(counter%n_cols)\n",
    "            img_array = skimage.transform.resize(imageio.imread(rc.test_dataset.imgs[counter][0]), (224,224), mode='constant', anti_aliasing=True)\n",
    "            ax[ii, jj].imshow(img_array, origin='lower')\n",
    "            ax[ii, jj].annotate( classlabel[lab.argmax()], xy=(10,10), color='white', size=10)\n",
    "            ax[ii, jj].annotate( classlabel[out.argmax()], xy=(120,10), color='cyan', size=10)\n",
    "            if lab.argmax != out.argmax():\n",
    "                ax[ii, jj].annotate( 'X', xy=(102,102), color='red', size=20)\n",
    "            for cc in range(5):\n",
    "                ax[ii, jj].annotate( '{}: {:.3f}'.format(classlabel[cc], torch.nn.Sigmoid()(out[cc])) , xy=(10,205-cc*20), color='white', size=10)\n",
    "            counter+=1\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Accuracy of the model on the {} test images: {} %'.format(accuracy.count, accuracy.avg*100))\n",
    "print('Classes: {}'.format(rc.classes))\n",
    "print('Confusion matrix:\\n', (confusion))\n",
    "\n",
    "confusion_2class = reduce_to_2_classes( confusion, [(0,1), (2,3,4)])\n",
    "print('Accuracy: {:.1f}%'.format(np.diag(confusion_2class).sum()/confusion_2class.sum()*100))\n",
    "print(confusion_2class)\n",
    "print('Sensitivity: {:.1f}%'.format(confusion_2class[1,1]/confusion_2class[:,1].sum()*100))\n",
    "print('Specificity: {:.1f}%'.format(confusion_2class[0,0]/confusion_2class[:,0].sum()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = labels.cpu().numpy()\n",
    "y_score = torch.nn.Sigmoid()(outputs).cpu().numpy()\n",
    "n_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, n_classes, True, True, figsize=(20,5))\n",
    "lw = 2\n",
    "for ii in range(n_classes):\n",
    "    ax[ii].plot(fpr[ii], tpr[ii], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[ii])\n",
    "    ax[ii].plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    ax[ii].set_xlim([0.0, 1.0])\n",
    "    ax[ii].set_ylim([0.0, 1.05])\n",
    "    ax[ii].set_xlabel('False Positive Rate')\n",
    "    ax[ii].legend(loc=\"lower right\")\n",
    "\n",
    "ax[0].set_ylabel('True Positive Rate')\n",
    "ax[int(n_classes/2)].set_title('Receiver operating characteristic example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
